{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmFSD6De7YRw",
        "outputId": "3a5f73fa-f828-4cee-913b-c326a5fa036e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gpFneIV57h0d"
      },
      "outputs": [],
      "source": [
        "# ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VD1JDIUJ9Mj8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Microbiota_composition.csv\")\n",
        "df = df.drop(\"Unnamed: 0\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KncmZtUF9OE7",
        "outputId": "d003ebbc-71bb-471b-d1f2-9ae82365f7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |   gamma   | learni... | max_depth | min_ch... | n_esti... |\n",
            "-------------------------------------------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.1498   \u001b[0m | \u001b[0m0.09556  \u001b[0m | \u001b[0m5.928    \u001b[0m | \u001b[0m1.599    \u001b[0m | \u001b[0m81.2     \u001b[0m |\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.0624   \u001b[0m | \u001b[0m0.01523  \u001b[0m | \u001b[0m6.465    \u001b[0m | \u001b[0m1.601    \u001b[0m | \u001b[0m191.6    \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.008234 \u001b[0m | \u001b[0m0.09729  \u001b[0m | \u001b[0m6.33     \u001b[0m | \u001b[0m1.212    \u001b[0m | \u001b[0m86.36    \u001b[0m |\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.07336  \u001b[0m | \u001b[0m0.03738  \u001b[0m | \u001b[0m5.099    \u001b[0m | \u001b[0m1.432    \u001b[0m | \u001b[0m108.2    \u001b[0m |\n",
            "| \u001b[95m5        \u001b[0m | \u001b[95m0.8052   \u001b[0m | \u001b[95m0.2447   \u001b[0m | \u001b[95m0.02255  \u001b[0m | \u001b[95m4.169    \u001b[0m | \u001b[95m1.366    \u001b[0m | \u001b[95m141.2    \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m0.7792   \u001b[0m | \u001b[0m0.341    \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m1.979    \u001b[0m | \u001b[0m154.9    \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m0.7468   \u001b[0m | \u001b[0m0.4      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m134.2    \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.03547  \u001b[0m | \u001b[0m0.02595  \u001b[0m | \u001b[0m3.709    \u001b[0m | \u001b[0m1.536    \u001b[0m | \u001b[0m143.6    \u001b[0m |\n",
            "| \u001b[95m9        \u001b[0m | \u001b[95m0.8182   \u001b[0m | \u001b[95m0.1874   \u001b[0m | \u001b[95m0.09937  \u001b[0m | \u001b[95m6.687    \u001b[0m | \u001b[95m1.432    \u001b[0m | \u001b[95m113.1    \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m0.8052   \u001b[0m | \u001b[0m0.323    \u001b[0m | \u001b[0m0.02582  \u001b[0m | \u001b[0m4.267    \u001b[0m | \u001b[0m1.269    \u001b[0m | \u001b[0m195.2    \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m0.8052   \u001b[0m | \u001b[0m0.1965   \u001b[0m | \u001b[0m0.03301  \u001b[0m | \u001b[0m5.941    \u001b[0m | \u001b[0m1.596    \u001b[0m | \u001b[0m209.6    \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.03019  \u001b[0m | \u001b[0m0.08307  \u001b[0m | \u001b[0m4.867    \u001b[0m | \u001b[0m1.306    \u001b[0m | \u001b[0m109.7    \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.033    \u001b[0m | \u001b[0m0.09134  \u001b[0m | \u001b[0m5.375    \u001b[0m | \u001b[0m1.75     \u001b[0m | \u001b[0m199.6    \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m0.8182   \u001b[0m | \u001b[0m0.2913   \u001b[0m | \u001b[0m0.07007  \u001b[0m | \u001b[0m6.978    \u001b[0m | \u001b[0m1.407    \u001b[0m | \u001b[0m157.7    \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m0.8052   \u001b[0m | \u001b[0m0.05343  \u001b[0m | \u001b[0m0.07635  \u001b[0m | \u001b[0m4.205    \u001b[0m | \u001b[0m1.19     \u001b[0m | \u001b[0m95.37    \u001b[0m |\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.1086   \u001b[0m | \u001b[0m0.06865  \u001b[0m | \u001b[0m3.249    \u001b[0m | \u001b[0m1.747    \u001b[0m | \u001b[0m241.9    \u001b[0m |\n",
            "| \u001b[95m17       \u001b[0m | \u001b[95m0.8247   \u001b[0m | \u001b[95m0.3349   \u001b[0m | \u001b[95m0.04362  \u001b[0m | \u001b[95m5.9      \u001b[0m | \u001b[95m1.473    \u001b[0m | \u001b[95m209.6    \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.2478   \u001b[0m | \u001b[0m0.01669  \u001b[0m | \u001b[0m5.637    \u001b[0m | \u001b[0m1.494    \u001b[0m | \u001b[0m209.7    \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.2022   \u001b[0m | \u001b[0m0.05605  \u001b[0m | \u001b[0m6.166    \u001b[0m | \u001b[0m1.33     \u001b[0m | \u001b[0m234.5    \u001b[0m |\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.1655   \u001b[0m | \u001b[0m0.06413  \u001b[0m | \u001b[0m6.671    \u001b[0m | \u001b[0m1.213    \u001b[0m | \u001b[0m113.1    \u001b[0m |\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.3371   \u001b[0m | \u001b[0m0.08099  \u001b[0m | \u001b[0m6.077    \u001b[0m | \u001b[0m1.639    \u001b[0m | \u001b[0m209.5    \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m0.7403   \u001b[0m | \u001b[0m0.2265   \u001b[0m | \u001b[0m0.01469  \u001b[0m | \u001b[0m4.457    \u001b[0m | \u001b[0m1.163    \u001b[0m | \u001b[0m80.98    \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.2612   \u001b[0m | \u001b[0m0.04527  \u001b[0m | \u001b[0m5.866    \u001b[0m | \u001b[0m1.554    \u001b[0m | \u001b[0m81.14    \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.1403   \u001b[0m | \u001b[0m0.08846  \u001b[0m | \u001b[0m6.676    \u001b[0m | \u001b[0m1.427    \u001b[0m | \u001b[0m113.0    \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m0.7273   \u001b[0m | \u001b[0m0.1746   \u001b[0m | \u001b[0m0.0236   \u001b[0m | \u001b[0m5.313    \u001b[0m | \u001b[0m1.725    \u001b[0m | \u001b[0m77.17    \u001b[0m |\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m0.7792   \u001b[0m | \u001b[0m0.3155   \u001b[0m | \u001b[0m0.07858  \u001b[0m | \u001b[0m5.868    \u001b[0m | \u001b[0m1.445    \u001b[0m | \u001b[0m209.7    \u001b[0m |\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m0.8117   \u001b[0m | \u001b[0m0.1726   \u001b[0m | \u001b[0m0.08515  \u001b[0m | \u001b[0m5.516    \u001b[0m | \u001b[0m1.13     \u001b[0m | \u001b[0m55.75    \u001b[0m |\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.3937   \u001b[0m | \u001b[0m0.04373  \u001b[0m | \u001b[0m3.825    \u001b[0m | \u001b[0m1.744    \u001b[0m | \u001b[0m184.9    \u001b[0m |\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m0.8052   \u001b[0m | \u001b[0m0.2602   \u001b[0m | \u001b[0m0.08665  \u001b[0m | \u001b[0m4.505    \u001b[0m | \u001b[0m1.962    \u001b[0m | \u001b[0m91.91    \u001b[0m |\n",
            "| \u001b[0m30       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.1854   \u001b[0m | \u001b[0m0.07852  \u001b[0m | \u001b[0m5.916    \u001b[0m | \u001b[0m1.902    \u001b[0m | \u001b[0m70.99    \u001b[0m |\n",
            "| \u001b[0m31       \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.1154   \u001b[0m | \u001b[0m0.09743  \u001b[0m | \u001b[0m3.79     \u001b[0m | \u001b[0m1.959    \u001b[0m | \u001b[0m245.2    \u001b[0m |\n",
            "| \u001b[0m32       \u001b[0m | \u001b[0m0.7273   \u001b[0m | \u001b[0m0.31     \u001b[0m | \u001b[0m0.01093  \u001b[0m | \u001b[0m3.875    \u001b[0m | \u001b[0m1.508    \u001b[0m | \u001b[0m123.5    \u001b[0m |\n",
            "| \u001b[0m33       \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.2501   \u001b[0m | \u001b[0m0.01251  \u001b[0m | \u001b[0m5.088    \u001b[0m | \u001b[0m1.611    \u001b[0m | \u001b[0m249.6    \u001b[0m |\n",
            "| \u001b[0m34       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.2162   \u001b[0m | \u001b[0m0.02051  \u001b[0m | \u001b[0m4.603    \u001b[0m | \u001b[0m1.665    \u001b[0m | \u001b[0m169.3    \u001b[0m |\n",
            "| \u001b[0m35       \u001b[0m | \u001b[0m0.8052   \u001b[0m | \u001b[0m0.318    \u001b[0m | \u001b[0m0.0526   \u001b[0m | \u001b[0m4.175    \u001b[0m | \u001b[0m1.711    \u001b[0m | \u001b[0m249.6    \u001b[0m |\n",
            "| \u001b[0m36       \u001b[0m | \u001b[0m0.7468   \u001b[0m | \u001b[0m0.2379   \u001b[0m | \u001b[0m0.02184  \u001b[0m | \u001b[0m6.3      \u001b[0m | \u001b[0m1.25     \u001b[0m | \u001b[0m91.82    \u001b[0m |\n",
            "| \u001b[0m37       \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.1361   \u001b[0m | \u001b[0m0.08692  \u001b[0m | \u001b[0m3.326    \u001b[0m | \u001b[0m1.422    \u001b[0m | \u001b[0m89.55    \u001b[0m |\n",
            "| \u001b[0m38       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.1723   \u001b[0m | \u001b[0m0.07339  \u001b[0m | \u001b[0m6.611    \u001b[0m | \u001b[0m1.621    \u001b[0m | \u001b[0m64.05    \u001b[0m |\n",
            "| \u001b[0m39       \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.107    \u001b[0m | \u001b[0m0.04723  \u001b[0m | \u001b[0m3.259    \u001b[0m | \u001b[0m1.775    \u001b[0m | \u001b[0m53.81    \u001b[0m |\n",
            "| \u001b[0m40       \u001b[0m | \u001b[0m0.7532   \u001b[0m | \u001b[0m0.1139   \u001b[0m | \u001b[0m0.01439  \u001b[0m | \u001b[0m3.382    \u001b[0m | \u001b[0m1.899    \u001b[0m | \u001b[0m244.8    \u001b[0m |\n",
            "| \u001b[0m41       \u001b[0m | \u001b[0m0.8117   \u001b[0m | \u001b[0m0.1104   \u001b[0m | \u001b[0m0.02173  \u001b[0m | \u001b[0m4.76     \u001b[0m | \u001b[0m1.451    \u001b[0m | \u001b[0m210.0    \u001b[0m |\n",
            "| \u001b[0m42       \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.3923   \u001b[0m | \u001b[0m0.02099  \u001b[0m | \u001b[0m4.367    \u001b[0m | \u001b[0m1.004    \u001b[0m | \u001b[0m115.2    \u001b[0m |\n",
            "| \u001b[95m43       \u001b[0m | \u001b[95m0.8312   \u001b[0m | \u001b[95m0.2031   \u001b[0m | \u001b[95m0.06874  \u001b[0m | \u001b[95m4.115    \u001b[0m | \u001b[95m1.871    \u001b[0m | \u001b[95m150.2    \u001b[0m |\n",
            "| \u001b[0m44       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.1125   \u001b[0m | \u001b[0m0.08868  \u001b[0m | \u001b[0m5.124    \u001b[0m | \u001b[0m1.494    \u001b[0m | \u001b[0m241.9    \u001b[0m |\n",
            "| \u001b[0m45       \u001b[0m | \u001b[0m0.7727   \u001b[0m | \u001b[0m0.2038   \u001b[0m | \u001b[0m0.03221  \u001b[0m | \u001b[0m3.908    \u001b[0m | \u001b[0m1.49     \u001b[0m | \u001b[0m148.3    \u001b[0m |\n",
            "| \u001b[0m46       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.03479  \u001b[0m | \u001b[0m0.08932  \u001b[0m | \u001b[0m6.317    \u001b[0m | \u001b[0m1.94     \u001b[0m | \u001b[0m151.4    \u001b[0m |\n",
            "| \u001b[0m47       \u001b[0m | \u001b[0m0.7857   \u001b[0m | \u001b[0m0.3372   \u001b[0m | \u001b[0m0.08541  \u001b[0m | \u001b[0m3.119    \u001b[0m | \u001b[0m1.745    \u001b[0m | \u001b[0m192.6    \u001b[0m |\n",
            "| \u001b[0m48       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.05883  \u001b[0m | \u001b[0m0.06416  \u001b[0m | \u001b[0m6.441    \u001b[0m | \u001b[0m1.688    \u001b[0m | \u001b[0m230.3    \u001b[0m |\n",
            "| \u001b[0m49       \u001b[0m | \u001b[0m0.7922   \u001b[0m | \u001b[0m0.2211   \u001b[0m | \u001b[0m0.06985  \u001b[0m | \u001b[0m3.887    \u001b[0m | \u001b[0m1.509    \u001b[0m | \u001b[0m58.75    \u001b[0m |\n",
            "| \u001b[0m50       \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.1906   \u001b[0m | \u001b[0m0.07903  \u001b[0m | \u001b[0m3.678    \u001b[0m | \u001b[0m1.81     \u001b[0m | \u001b[0m165.7    \u001b[0m |\n",
            "| \u001b[0m51       \u001b[0m | \u001b[0m0.7597   \u001b[0m | \u001b[0m0.04357  \u001b[0m | \u001b[0m0.03397  \u001b[0m | \u001b[0m3.754    \u001b[0m | \u001b[0m1.474    \u001b[0m | \u001b[0m75.62    \u001b[0m |\n",
            "| \u001b[0m52       \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.3651   \u001b[0m | \u001b[0m0.04714  \u001b[0m | \u001b[0m4.786    \u001b[0m | \u001b[0m1.691    \u001b[0m | \u001b[0m230.5    \u001b[0m |\n",
            "| \u001b[0m53       \u001b[0m | \u001b[0m0.7987   \u001b[0m | \u001b[0m0.3888   \u001b[0m | \u001b[0m0.05287  \u001b[0m | \u001b[0m6.885    \u001b[0m | \u001b[0m1.443    \u001b[0m | \u001b[0m149.7    \u001b[0m |\n"
          ]
        }
      ],
      "source": [
        "# Features\n",
        "X = df.drop(columns=[\"condition\"], axis=1)\n",
        "\n",
        "# Target\n",
        "y = df[\"condition\"]\n",
        "\n",
        "# lambda to scale the target into numeric (CRC : 1, control : 0)\n",
        "y = y.apply(lambda x: 1 if x == \"CRC\" else 0)\n",
        "\n",
        "# Split df into train and test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Boolean filter to keep numeric column\n",
        "numeric_features = df.select_dtypes(include=['number']).columns\n",
        "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
        "\n",
        "# Selection of the categorical feature to preprocess\n",
        "# categorical_feature = X.select_dtypes(exclude=['number']).columns\n",
        "# feature_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop=\"first\"))])\n",
        "\n",
        "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        # (\"cat\", feature_transformer, categorical_feature),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Prétraitement des données (X_train, X_test) avec une normalisation\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "# input_shape = X_train_scaled.shape[1]\n",
        "\n",
        "# Définir la fonction d'évaluation\n",
        "def evaluate_xgb(n_estimators, max_depth, learning_rate, gamma, min_child_weight):\n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=int(n_estimators),\n",
        "        max_depth=int(max_depth),\n",
        "        learning_rate=learning_rate,\n",
        "        gamma=gamma,\n",
        "        objective='binary:logistic',\n",
        "        min_child_weight=min_child_weight,\n",
        "        random_state=42\n",
        "        )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Définir l'espace de recherche\n",
        "pbounds = {\n",
        "    'n_estimators': (50, 250),\n",
        "    'max_depth': (3, 6),\n",
        "    'learning_rate': (0.01, 0.1),\n",
        "    'gamma': (0, 0.4),\n",
        "    'min_child_weight': (1, 2)\n",
        "    }\n",
        "\n",
        "# Initialiser l'optimiseur bayésien\n",
        "optimizer = BayesianOptimization(f=evaluate_xgb, pbounds=pbounds, random_state=42)\n",
        "\n",
        "# Lancer l'optimisation\n",
        "optimizer.maximize(init_points=5, n_iter=50)\n",
        "\n",
        "# Récupérer les hyperparamètres optimaux\n",
        "best_params = optimizer.max['params']\n",
        "\n",
        "# Entraîner le modèle final avec les meilleurs hyperparamètres\n",
        "best_model = xgb.XGBClassifier(n_estimators=int(best_params['n_estimators']),\n",
        "                           max_depth=int(best_params['max_depth']),\n",
        "                           learning_rate=best_params['learning_rate'],\n",
        "                           gamma=best_params['gamma'],\n",
        "                           min_child_weight=best_params['min_child_weight'])\n",
        "best_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSPCfwAaxPja"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
